{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft\n",
    "import time\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_values():\n",
    "    training_path = \"NguyenAmHuanLuyen-16k\"\n",
    "    test_path = \"NguyenAmKiemThu-16k\"\n",
    "    training_folders = [folder for folder in os.listdir(training_path) if os.path.isdir(os.path.join(training_path, folder))]\n",
    "    test_folders = [folder for folder in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, folder))]\n",
    "    vowel_files = [\"a.wav\", \"e.wav\", \"i.wav\", \"o.wav\", \"u.wav\"]\n",
    "    frame_duration = 0.03\n",
    "    frame_shift = 0.015\n",
    "    N_FFT_array = [512, 1024, 2048]\n",
    "\n",
    "    return training_path, training_folders, test_path, test_folders, vowel_files, frame_duration, frame_shift, N_FFT_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def process_speech_signal(path, folder, file, frame_duration, frame_shift):\n",
    "    filepath = f\"{path}/{folder}/{file}\"\n",
    "    warnings.filterwarnings('ignore', category=wavfile.WavFileWarning)\n",
    "    Fs, data = wavfile.read(filepath)\n",
    "    T = 1 / Fs                            # Thoi gian lay mau\n",
    "    n = len(data)                         # So mau tin hieu\n",
    "    t = n * T                             # Thoi gian tin hieu\n",
    "    signal = data\n",
    "    data = data / abs(max(data))          # Chuan hoa bien do ve [-1, 1]\n",
    "    # Number of samples in one frame (20ms)\n",
    "    frame_len = round(frame_duration * Fs)\n",
    "    # Number of samples to shift the frame (10ms)\n",
    "    frame_shift_len = round(frame_shift * Fs)\n",
    "    # Total number of frames\n",
    "    n_f = int(np.floor((n - frame_len) / frame_shift_len) + 1)\n",
    "    # Split the data into frames\n",
    "    list_frames = [data[i * frame_shift_len:i * frame_shift_len + frame_len] for i in range(n_f)]\n",
    "    frames = np.array(list_frames)\n",
    "    # Calculate Short-Time Energy (STE) for each frame\n",
    "    ste = np.sum(np.square(frames), axis=1)\n",
    "    # Normalize STE to the range [0, 1]\n",
    "    ste = ste / max(ste)\n",
    "    # IDs containing speech frames\n",
    "    id = np.where(ste >= 0.03)[0]\n",
    "    # Calculate the length of the ID array\n",
    "    len_id = len(id)\n",
    "    distance = int(np.ceil((id[-1] - id[0]) / 3))\n",
    "    frame_start = id[0] + distance\n",
    "    frame_end = id[0] + 2 * distance\n",
    "\n",
    "    # Plotting the signal and the STE\n",
    "    # plt.figure()\n",
    "    # plt.plot(np.arange(0, len(signal) * T, T), signal) # Original signal\n",
    "    # plt.title(\"Signal and (STE) of the Signal \" + f\"{folder}/{file}\")\n",
    "    # # Vertical lines for speech marks\n",
    "    # plt.axvline(x=(id[0]) * frame_shift_len * T, color='r', linestyle='--', label=\"Start of Speech\")\n",
    "    # plt.axvline(x=(id[-1]) * frame_shift_len * T, color='r', linestyle='--', label=\"End of Speech\")\n",
    "    # plt.axvline(x=(frame_start) * frame_shift_len * T, color='b', linestyle='--', label=\"Start of Stable Speech\")\n",
    "    # plt.axvline(x=(frame_end) * frame_shift_len * T, color='b', linestyle='--', label=\"End of Stable Speech\")\n",
    "    # plt.xlabel(\"Time (s)\")\n",
    "    # plt.ylabel(\"Amplitude\")\n",
    "    # plt.legend()\n",
    "    # plt.tight_layout()\n",
    "    # plt.show() \n",
    "    return frames, frame_start, frame_end\n",
    "# Example usage\n",
    "# frames, frame_start, frame_end = process_speech_signal(\"NguyenAmHuanLuyen-16k\", \"23MTL\", \"a.wav\", 0.02, 0.01)\n",
    "# frames, frame_start, frame_end = process_speech_signal(\"NguyenAmHuanLuyen-16k\", \"23MTL\", \"o.wav\", 0.02, 0.01)\n",
    "# frames, frame_start, frame_end = process_speech_signal(\"NguyenAmHuanLuyen-16k\", \"23MTL\", \"u.wav\", 0.02, 0.01)\n",
    "# frames, frame_start, frame_end = process_speech_signal(\"NguyenAmHuanLuyen-16k\", \"23MTL\", \"e.wav\", 0.02, 0.01)\n",
    "# frames, frame_start, frame_end = process_speech_signal(\"NguyenAmHuanLuyen-16k\", \"23MTL\", \"i.wav\", 0.02, 0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_characteristic_vector_fft(frames, frame_start, frame_end, N_FFT):\n",
    "    # window = hamming(frames.shape[1]) # tao cua so hamming co do dai bang do dai khung tin hieu, giup giam hieu ung ro ri pho (Spectral Leakage)\n",
    "    # window = np.ones(frames.shape[1]) # tao cua so hinh chu nhat\n",
    "    # window = np.hanning(frames.shape[1]) # tao cua so hanning\n",
    "    # window = np.blackman(frames.shape[1]) # tao cua so blackman\n",
    "    window = np.hamming(frames.shape[1]) # tao cua so hamming\n",
    "\n",
    "    # Khởi tạo vector đặc trưng\n",
    "    characteristic_vector = np.zeros(N_FFT)\n",
    "    for k in range(frame_start, frame_end + 1):\n",
    "        frame_vector = window * frames[k]\n",
    "        kernel = np.array([1/3, 1/3, 1/3]) # tao bo loc trung binh de lam muot tin hieu\n",
    "        frame_filtered = np.convolve(frame_vector, kernel, mode='same')\n",
    "        characteristic_vector += np.abs(fft(frame_filtered, N_FFT))\n",
    "\n",
    "        # frame_vector = window * frames[k]\n",
    "        # characteristic_vector += np.abs(fft(frame_vector, N_FFT))\n",
    "    characteristic_vector /= (frame_end + 1 - frame_start) # vector dac trung trung binh\n",
    "    return characteristic_vector\n",
    "    \n",
    "\n",
    "def draw_characteristic_vectors_fft(vowel_files, vectors, N_FFT, title):\n",
    "    Fs = 16000\n",
    "    freq = np.linspace(0, Fs/2, int(N_FFT/2))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(freq, vectors[0, :int(N_FFT/2)], 'r', label=vowel_files[0])\n",
    "    plt.plot(freq, vectors[1, :int(N_FFT/2)], 'g', label=vowel_files[1])\n",
    "    plt.plot(freq, vectors[2, :int(N_FFT/2)], 'b', label=vowel_files[2])\n",
    "    plt.plot(freq, vectors[3, :int(N_FFT/2)], 'y', label=vowel_files[3])\n",
    "    plt.plot(freq, vectors[4, :int(N_FFT/2)], 'k', label=vowel_files[4])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Tần số (Hz)')\n",
    "    plt.ylabel('Biên đô FFT')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def training_for_vowel_recognition_using_FFT(training_path, training_folders, vowel_files, frame_duration, frame_shift, N_FFT):\n",
    "    vowels_size = len(vowel_files)\n",
    "    folders_size = len(training_folders)\n",
    "\n",
    "    vectors = np.zeros((vowels_size, N_FFT))\n",
    "    for i in range(vowels_size):\n",
    "        sum_of_characteristic_vectors = np.zeros(N_FFT)\n",
    "        for j in range(folders_size):\n",
    "            # Phan doan tin hieu de lay vung tin hieu on dinh\n",
    "            frames, frame_start, frame_end = process_speech_signal(training_path, training_folders[j], vowel_files[i], frame_duration, frame_shift)\n",
    "            # Tinh vector dac trung\n",
    "            sum_of_characteristic_vectors += find_characteristic_vector_fft(frames, frame_start, frame_end, N_FFT)\n",
    "        vectors[i, :] = sum_of_characteristic_vectors / folders_size\n",
    "\n",
    "    title = f\"Vector đặc trưng FFT với N_FFT = {N_FFT}\"\n",
    "    draw_characteristic_vectors_fft(vowel_files, vectors, N_FFT, title)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vector1, vector2):\n",
    "    distance = np.sqrt(np.sum((vector1 - vector2) ** 2))\n",
    "    return distance\n",
    "\n",
    "def calc_recognition_accuracy(confusion_matrix, folders_size, vowel_files_size):\n",
    "    total_percent = 0\n",
    "    for i in range(vowel_files_size):\n",
    "        # Tinh do chinh xac nhan dang moi nguyen am\n",
    "        percent = float(confusion_matrix[i + 1][i + 1]) / folders_size * 100\n",
    "        confusion_matrix[i + 1][vowel_files_size + 2] = percent\n",
    "        total_percent += percent\n",
    "    confusion_matrix[vowel_files_size + 1][vowel_files_size + 2] = total_percent / vowel_files_size\n",
    "    # print(confusion_matrix)\n",
    "    return confusion_matrix\n",
    "\n",
    "def testing_for_vowel_recognition_using_FFT(test_path, test_folders, vowel_files, frame_duration, frame_shift, N_FFT, vectors):\n",
    "    folders_size = len(test_folders)\n",
    "    vowel_files_size = len(vowel_files)\n",
    "    vowels = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
    "\n",
    "    result = np.zeros((folders_size + 1, vowel_files_size + 1), dtype=object)\n",
    "    result[0, 0] = \"\"\n",
    "    result[1:, 0] = test_folders\n",
    "    result[0, 1:] = vowels\n",
    "\n",
    "    confusion_matrix = [\n",
    "        [\"\", \"a\", \"e\", \"i\", \"o\", \"u\", \"Thời gian(ms)\", \"Độ chính xác(%)\"],\n",
    "        [\"a\", 0, 0, 0, 0, 0, 0, 0],\n",
    "        [\"e\", 0, 0, 0, 0, 0, 0, 0],\n",
    "        [\"i\", 0, 0, 0, 0, 0, 0, 0],\n",
    "        [\"o\", 0, 0, 0, 0, 0, 0, 0],\n",
    "        [\"u\", 0, 0, 0, 0, 0, 0, 0],\n",
    "        [\"Độ chính xác trung bình(%)\", \"\", \"\", \"\", \"\", \"\", 0, 0]\n",
    "    ]\n",
    "\n",
    "    for i in range(folders_size):\n",
    "        time_processing_vowel = 0\n",
    "        for j in range(vowel_files_size):\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Danh dau vung co dac trung pho on dinh dac trung cho nguyen am\n",
    "            frames, frame_start, frame_end = process_speech_signal(test_path, test_folders[i], vowel_files[j], frame_duration, frame_shift)\n",
    "            # Tinh vector dac trung cho nguyen am bang FFT cua tung nguyen am cua tung nguoi noi\n",
    "            characteristic_vector_of_current_vowel = find_characteristic_vector_fft(frames, frame_start, frame_end, N_FFT)\n",
    "            \n",
    "            # Tinh khoang cach euclidean_distance giua vector nguyen am kiem thu va cac vector huan luyen cua 5 nguyen am [a, e, i, o, u] de nhan dang nguyen am\n",
    "            min_distance = euclidean_distance(vectors[0, :], characteristic_vector_of_current_vowel)\n",
    "            index = 0\n",
    "            for k in range(1, vowel_files_size):\n",
    "                distance = euclidean_distance(vectors[k, :], characteristic_vector_of_current_vowel)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    index = k\n",
    "\n",
    "            end_time = time.time()\n",
    "            # Tinh thoi gian nhan dang trung binh\n",
    "            confusion_matrix[j + 1][vowel_files_size + 1] += (end_time - start_time) * 1000 / folders_size\n",
    "            confusion_matrix[vowel_files_size + 1][vowel_files_size + 1] += (end_time - start_time) * 1000 / (folders_size * vowel_files_size)\n",
    "            # Dien ket qua vao bang ket qua va ma tran nham lan\n",
    "            result[i + 1, j + 1] = vowels[index]\n",
    "            confusion_matrix[j + 1][index + 1] += 1\n",
    "\n",
    "\n",
    "    # Tinh phan tram nhan dang dung va sai\n",
    "    confusion_matrix = calc_recognition_accuracy(confusion_matrix, len(test_folders), len(vowel_files))\n",
    "\n",
    "    # print(result)\n",
    "    # print(confusion_matrix)\n",
    "    return result, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_result_matrix(result_matrix, N_FFT):\n",
    "    # Hien thi bang ket qua\n",
    "    figure, axes = plt.subplots()\n",
    "    title = f\"Kết quả nhận dạng nguyên âm bằng FFT với N_FFT = {N_FFT}\"\n",
    "    axes.set_title(title, color=\"blue\", loc='center')\n",
    "    axes.axis('off')\n",
    "    axes.axis('tight')\n",
    "    axes.table(cellText=result_matrix, loc='center')\n",
    "    figure.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_confusion_matrix(confusion_matrix, N_FFT):\n",
    "    # Dinh dang ket qua hien thi do chinh xac lam tron 4 chu so thap phan, cac gia tri khong phai so thuc thi hien thi rong\n",
    "    for row in confusion_matrix[1:]:\n",
    "        if type(row[-1]) == float:  # Kiem tra dinh dang so thuc\n",
    "            row[-1] = \"{:.1f}\".format(row[-1])\n",
    "            row[-2] = round(row[-2], 1)\n",
    "        else:\n",
    "            row[-1] = \"\"  # Neu khong phai so thuc thi hien thi rong\n",
    "    # Chuyen confusion_matrix thanh DataFrame de xu ly de dang hon\n",
    "    df_cm = DataFrame(\n",
    "        [row[1:] for row in confusion_matrix[1:]],  # Loai tru cot tieu de, confusion_matrix[1:] la loai tru hang tieu de trong confusion_matrix\n",
    "        columns=confusion_matrix[0][1:],  # Hang dau tien de hien thi ten nguyen am nhan dang duoc, o dau tien de trong\n",
    "        index=[row[0] for row in confusion_matrix[1:]]  # Cot dau tien de hien thi folder nguoi noi, confusion_matrix[1:] la loai tru hang tieu de trong confusion_matrix\n",
    "    )\n",
    "    # Hien thi ma tran nham lan\n",
    "    figure, axes = plt.subplots(figsize=(12, 4))\n",
    "    title = f\"Ma trận nhầm lẫn bằng FFT với N_FFT = {N_FFT}\"\n",
    "    axes.set_title(title, color=\"blue\", loc='center')\n",
    "    axes.axis('off')  # Ẩn các trục\n",
    "    axes.axis('tight')  # Ẩn khoảng trắng thừa\n",
    "    tab = axes.table(cellText=df_cm.values, cellLoc='center', loc='center', rowLabels=df_cm.index, colLabels=df_cm.columns)\n",
    "    tab.auto_set_font_size(False)\n",
    "    tab.set_fontsize(10)\n",
    "    tab.scale(1, 1.5)\n",
    "    figure.tight_layout()\n",
    "\n",
    "    # Highlight hang co do chinh xac cao nhat va thap nhat\n",
    "    max_index = df_cm.iloc[:-1, -1].astype(float).idxmax()  # Do chinh xac cao nhat khong tinh do chinh xac trung binh\n",
    "    min_index = df_cm.iloc[:-1, -1].astype(float).idxmin()  # Do chinh xac thap nhat khong tinh do chinh xac trung binh\n",
    "\n",
    "    for key, cell in tab.get_celld().items():\n",
    "        if key[0] == 0:\n",
    "            cell.set_text_props(color='black', fontweight='bold')\n",
    "            cell.set_facecolor('lightgrey')\n",
    "\n",
    "    for (i, row) in enumerate(df_cm.iterrows(), start=1):\n",
    "        if row[0] == max_index :  # Highlight hang do chinh xac cao nhat\n",
    "            for j in range(len(df_cm.columns)):\n",
    "                tab[(i, j)].set_facecolor('lightgreen')\n",
    "        if row[0] == min_index:  # Highlight hang do chinh xac thap nhat\n",
    "            for j in range(len(df_cm.columns)):\n",
    "                tab[(i, j)].set_facecolor('salmon')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bai2(training_path, training_folders, test_path, test_folders, vowel_files, N_FFT_array, frame_duration, frame_shift):\n",
    "    for N_FFT in N_FFT_array:\n",
    "        # Huan luyen nhan dang nguyen am bang FFT\n",
    "        vectors = training_for_vowel_recognition_using_FFT(training_path, training_folders, vowel_files, frame_duration, frame_shift, N_FFT)\n",
    "        # Kiem thu nhan dang nguyen am bang FFT\n",
    "        result, confusion_matrix = testing_for_vowel_recognition_using_FFT(test_path, test_folders, vowel_files, frame_duration, frame_shift, N_FFT, vectors)\n",
    "        # Hien thi bang ket qua nhan dang\n",
    "        draw_result_matrix(result, N_FFT)\n",
    "        # Hien thi ma tran nham lan\n",
    "        draw_confusion_matrix(confusion_matrix, N_FFT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khoi tao gia tri\n",
    "training_path, training_folders, test_path, test_folders, vowel_files, frame_duration, frame_shift, N_FFT_array = initialize_values()\n",
    "#Bai2 - Nhan dang nguyen am dung dac trung pho FFT\n",
    "Bai2(training_path, training_folders, test_path, test_folders, vowel_files, N_FFT_array, frame_duration, frame_shift)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
